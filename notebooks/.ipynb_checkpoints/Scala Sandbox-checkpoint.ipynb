{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name: Compile Error\n",
       "Message: <console>:18: error: not found: value spark\n",
       "         import spark._\n",
       "                ^\n",
       "StackTrace: "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spark._\n",
    "import spark.streaming._\n",
    "import StreamingContext._\n",
    "import TutorialHelper._\n",
    "\n",
    "object Tutorial {\n",
    "  def main(args: Array[String]) {\n",
    "    \n",
    "    // Location of the Spark directory\n",
    "    val sparkHome = \"/root/spark\"\n",
    "    \n",
    "    // URL of the Spark cluster\n",
    "    val sparkUrl = getSparkUrl()\n",
    "    \n",
    "    // Location of the required JAR files\n",
    "    val jarFile = \"target/scala-2.9.3/tutorial_2.9.3-0.1-SNAPSHOT.jar\"\n",
    "    \n",
    "    // HDFS directory for checkpointing\n",
    "    val checkpointDir = TutorialHelper.getHdfsUrl() + \"/checkpoint/\"\n",
    "    \n",
    "    // Configure Twitter credentials using twitter.txt\n",
    "    TutorialHelper.configureTwitterCredentials()\n",
    "    \n",
    "    // Your code goes here\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name: Compile Error\n",
       "Message: <console>:18: error: not found: type StreamingContext\n",
       "         val ssc = new StreamingContext(sparkUrl, \"Tutorial\", Seconds(1), sparkHome, Seq(jarFile))\n",
       "                       ^\n",
       "StackTrace: "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val ssc = new StreamingContext(sparkUrl, \"Tutorial\", Seconds(1), sparkHome, Seq(jarFile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Range(1, 2, 3, 4, 5, 6, 7, 8, 9, 10)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 to 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name: Compile Error\n",
       "Message: <console>:19: error: value DRIVER_IDENTIFIER in object SparkContext cannot be accessed in object org.apache.spark.SparkContext\n",
       "              DRIVER_IDENTIFIER\n",
       "              ^\n",
       "StackTrace: "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name: Compile Error\n",
       "Message: <console>:18: error: not found: value spark\n",
       "         import spark.streaming._\n",
       "                ^\n",
       "StackTrace: "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spark.streaming._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala 2.10 (Spark 1.6.0)",
   "language": "scala",
   "name": "toree"
  },
  "language_info": {
   "name": "scala"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
