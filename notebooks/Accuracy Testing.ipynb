{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analisys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After considering many alternatives, for the sentiment analysis I decided to test of the very few algorithms that go a long way to address compositionality, which the algorithms based of bag-of-words models cannot address: simply attributing a polarity to the single words does not always lead the right result.\n",
    "\n",
    "I tested Stanford's reimplementation of the [Recursive Neural Tensor Networks by Socher et al.](http://nlp.stanford.edu/~socherr/EMNLP2013_RNTN.pdf).\n",
    "\n",
    "They applied their system to a corpus of ~11k movie reviews from Rotten Tomatoes, and made the trained model available through the Stanford CoreNLP system.\n",
    "\n",
    "Although I considered reimplementing their system, I started out by verifying the possibility of domain transfer. Kaggle has made available a labled [dataset of airline tweets](https://www.kaggle.com/crowdflower/twitter-airline-sentiment).\n",
    "\n",
    "The problem is complicate by the different domain, but also by the fact that Twitter texts are short, are difficult to parse, and difficult to interpret even for humans.\n",
    "\n",
    "The results have surprised me. The following describes the way I tested the accuracy of the resulting system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Input and test files\n",
    "\n",
    "Since my purpose is not train and test a model, instead of divdidind the labeled input in three parts as usual, I used all the ~14.5 items in the Kaggle dataset to evaluate the already trained model provided by the Stanford software. \n",
    "\n",
    "* An input JSON file (`tweets.json`) is prepared from the dataset;\n",
    "* such file is processed by the Scala code (`AccuracyTest.process`);\n",
    "* the output, `analyzed.json`, is evaluated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sqlite3, codecs\n",
    "from json import dumps\n",
    "\n",
    "# This is the database containing the labeled Airline data\n",
    "conn = sqlite3.connect('../data/airline-twitter-sentiment/database.sqlite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Turn positive -> +, negative -> -, neuteral -> =.\n",
    "def to_symbol(s):\n",
    "    if s.lower().startswith('pos'): return '+'\n",
    "    elif s.lower().startswith('neg'): return '-'\n",
    "    else: return '='\n",
    "\n",
    "sql = 'select airline_sentiment, text from tweets'\n",
    "\n",
    "js_docs = (dumps({'polarity': to_symbol(polarity), \n",
    "                  'text': text}) \n",
    "           for (polarity, text) in conn.execute(sql))\n",
    "\n",
    "with codecs.open('../data/airline-twitter-sentiment/tweets.json', mode='w+', encoding='utf-8') as os:\n",
    "    os.write(u'\\n'.join(js_docs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Input file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"polarity\": \"=\", \"text\": \"@JetBlue's new CEO seeks the right balance to please passengers and Wall ... - Greenfield Daily Reporter http://t.co/LM3opxkxch\"}\r\n",
      "{\"polarity\": \"-\", \"text\": \"@JetBlue is REALLY getting on my nerves !! \\ud83d\\ude21\\ud83d\\ude21 #nothappy\"}\r\n",
      "{\"polarity\": \"-\", \"text\": \"@united yes. We waited in line for almost an hour to do so. Some passengers just left not wanting to wait past 1am.\"}\r\n",
      "{\"polarity\": \"-\", \"text\": \"@united the we got into the gate at IAH on time and have given our seats and closed the flight. If you know people is arriving, have to wait\"}\r\n",
      "{\"polarity\": \"-\", \"text\": \"@SouthwestAir its cool that my bags take a bit longer, dont give me baggage blue balls-turn the carousel on, tell me it's coming, then not.\"}\r\n"
     ]
    }
   ],
   "source": [
    "!head -n 5 ../data/airline-twitter-sentiment/tweets.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The following file is the output of `AccracyTest.process` (in `src/main/scala/BasicTask.scala`) with the above file as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   14485 ../data/airline-twitter-sentiment/analyzed.json\r\n"
     ]
    }
   ],
   "source": [
    "!wc -l ../data/airline-twitter-sentiment/analyzed.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"text\":\"@JetBlue's new CEO seeks the right balance to please passengers and Wall ... - Greenfield Daily Reporter http://t.co/LM3opxkxch\",\"polarity\":\"=\",\"sentiment\":3.0}\r\n",
      "{\"text\":\"@JetBlue is REALLY getting on my nerves !! \\ud83d\\ude21\\ud83d\\ude21 #nothappy\",\"polarity\":\"-\",\"sentiment\":1.5}\r\n",
      "{\"text\":\"@united yes. We waited in line for almost an hour to do so. Some passengers just left not wanting to wait past 1am.\",\"polarity\":\"-\",\"sentiment\":1.6666666666666667}\r\n",
      "{\"text\":\"@united the we got into the gate at IAH on time and have given our seats and closed the flight. If you know people is arriving, have to wait\",\"polarity\":\"-\",\"sentiment\":2.5}\r\n",
      "{\"text\":\"@SouthwestAir its cool that my bags take a bit longer, dont give me baggage blue balls-turn the carousel on, tell me it's coming, then not.\",\"polarity\":\"-\",\"sentiment\":1.0}\r\n"
     ]
    }
   ],
   "source": [
    "!head -n 5 ../data/airline-twitter-sentiment/analyzed.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The file is read in to be evauated.\n",
    "\n",
    "_Small note_: both Python 2 and 3 split lines on all Unicode characters with the Line_Break propery, which is unfortunate, since some of those can show up in the tweets. That's why I need to read in the entire file in memory and split it over the ASCII newline. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from json import loads\n",
    "with open('../data/airline-twitter-sentiment/analyzed.json', encoding='utf-8') as lines:\n",
    "    s = lines.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14485"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jss = [loads(l, encoding='utf-8') for l in s.split('\\n') if l]\n",
    "len(jss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14485"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jss_df = pd.DataFrame(jss)\n",
    "N = len(jss_df); N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* A small sample of the test Tweets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>polarity</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1619</th>\n",
       "      <td>-</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>@USAirways has an SPF record error that is cau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1252</th>\n",
       "      <td>-</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>@united once again my bag is lost when I trave...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11169</th>\n",
       "      <td>=</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>@jetblue it's time for a direct flight from #J...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6551</th>\n",
       "      <td>+</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>@JetBlue ok!!! That's super helpful. Thank you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5779</th>\n",
       "      <td>-</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>@SouthwestAir been on hold to rebook a flight ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1797</th>\n",
       "      <td>=</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>â€œ@SouthwestAir: @saysorrychris Can you follow ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7729</th>\n",
       "      <td>-</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>@USAirways using all of my monthly minute on h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6373</th>\n",
       "      <td>+</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>@VirginAmerica Thanks for a great flight from ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8708</th>\n",
       "      <td>+</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>@united Thank y'all for being an amazing airli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5882</th>\n",
       "      <td>+</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>@VirginAmerica thanks guys! Sweet route over t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14475</th>\n",
       "      <td>=</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>@JetBlue flight 1041 to Savannah, GA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2205</th>\n",
       "      <td>=</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>@USAirways Thanks. Suggestion: stop the promo ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5315</th>\n",
       "      <td>-</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>@united Yes I needed plenty of assistance but ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6566</th>\n",
       "      <td>-</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>@USAirways why the hell u left *alliance and j...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2254</th>\n",
       "      <td>=</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>@SouthwestAir snapchat, iMessage, instagram......</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      polarity  sentiment                                               text\n",
       "1619         -   1.000000  @USAirways has an SPF record error that is cau...\n",
       "1252         -   1.500000  @united once again my bag is lost when I trave...\n",
       "11169        =   1.000000  @jetblue it's time for a direct flight from #J...\n",
       "6551         +   2.250000  @JetBlue ok!!! That's super helpful. Thank you...\n",
       "5779         -   1.500000  @SouthwestAir been on hold to rebook a flight ...\n",
       "1797         =   2.000000  â€œ@SouthwestAir: @saysorrychris Can you follow ...\n",
       "7729         -   2.000000  @USAirways using all of my monthly minute on h...\n",
       "6373         +   2.500000  @VirginAmerica Thanks for a great flight from ...\n",
       "8708         +   3.000000  @united Thank y'all for being an amazing airli...\n",
       "5882         +   2.500000  @VirginAmerica thanks guys! Sweet route over t...\n",
       "14475        =   1.000000               @JetBlue flight 1041 to Savannah, GA\n",
       "2205         =   1.666667  @USAirways Thanks. Suggestion: stop the promo ...\n",
       "5315         -   1.000000  @united Yes I needed plenty of assistance but ...\n",
       "6566         -   2.000000  @USAirways why the hell u left *alliance and j...\n",
       "2254         =   1.000000  @SouthwestAir snapchat, iMessage, instagram......"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jss_df.sample(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Sanity check: we want to get an idea of how the system has labeled the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sentiment(pol):\n",
    "    return jss_df[jss_df['polarity'] == pol]['sentiment']\n",
    "    \n",
    "def mean_std(df):\n",
    "    m, s = df.mean(), df.std()\n",
    "    return m - s, m, m + s\n",
    "\n",
    "desc = [mean_std(s) for s in map(sentiment, ('-', '=', '+'))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Stanford sentiment analzer has five lables (from 0 to 4). These are the $(\\bar{x_i} - \\sigma, \\bar{x_i}, \\bar{x_i} + \\sigma)$ tuples for the negative, neutral and positive polarity items. There is quite a bit of overlap:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.95509820978792059, 1.4426183135663428, 1.9301384173447651),\n",
       " (1.0485336944830861, 1.6355839501000793, 2.2226342057170725),\n",
       " (1.5285735260682785, 2.2019647447668018, 2.8753559634653252)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy\n",
    "\n",
    "We compute here the score according to the guidelines for [Semeval 2015, task 10](http://alt.qcri.org/semeval2015/task10/), subtask B:\n",
    "\n",
    "> **Subtask B**: Message Polarity Classification: Given a message, classify whether the message is of positive, negative, or neutral sentiment. For messages conveying both a positive and negative sentiment, whichever is the stronger sentiment should be chosen.\n",
    "\n",
    "The score is $$ \\frac{F_1^{pos} + F_1^{neg}}{2}. $$\n",
    "\n",
    "Since the Stanford sentment analyzer returns five labels from 0 to 4 (strongly negative, negative, neutral, positive, strongly positive) but seems more than a bit biased towards the lower end of the spectrum, I'm using a rather arbitary 2.0 as the cutoff between the \"positive\" and \"negative\" classes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score Semeval 2015: 66.31%\n"
     ]
    }
   ],
   "source": [
    "def prec_rec(true_p, predict_p):\n",
    "    \"\"\"Takes two predicates that evaluate a true and predicted\n",
    "    retrult, and returns a tuple with precision and recall.\n",
    "    \"\"\"\n",
    "    true_count, predict_count, correct_count = 0, 0, 0\n",
    "    for js in jss:\n",
    "        if true_p(js):\n",
    "            true_count += 1\n",
    "        if predict_p(js):\n",
    "            predict_count += 1\n",
    "        if true_p(js) and predict_p(js):\n",
    "            correct_count += 1\n",
    "#     print(true_count, predict_count, correct_count)\n",
    "    return correct_count / predict_count, correct_count / true_count\n",
    "\n",
    "cutoff = 2.0\n",
    "true_pos = lambda js: js['polarity'] == '+'\n",
    "pred_pos = lambda js: js['sentiment'] > cutoff\n",
    "\n",
    "true_neg = lambda js: js['polarity'] == '-'\n",
    "pred_neg = lambda js: js['sentiment'] <= cutoff\n",
    "\n",
    "def F1(true_p, pred_p):\n",
    "    p, r = prec_rec(true_p, pred_p) \n",
    "    return 2 * p * r / (p + r)\n",
    "\n",
    "F1_pos = F1(true_pos, pred_pos)\n",
    "F1_neg = F1(true_neg, pred_neg)\n",
    "\n",
    "score = (F1_pos + F1_neg) / 2\n",
    "print('Score Semeval 2015: %.2f%%' % (score * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To note\n",
    "\n",
    "Such score is, to me at least, rather suprising: it's actually slightly **better** than the ones reported as the [official results](https://docs.google.com/document/d/1WV-XTvQDpuH_IfKrjzeZ361s1ykcskDNNuOV3oI39_c/edit) for the task (they range between 60.77 and 64.84). In fairness, it certainly would need to be tested on the Semeval dataset, but the evidence is that it performs well on the present one.\n",
    "\n",
    "The result is suprising for two reasons:\n",
    "\n",
    "* the model was trained on movie reviews, but it generalizes over certain language patterns that might be common to the two domains;\n",
    "* despite there being no provision in the code for dealing with the quirkiness of Twitter texts, the score is still comparable to the output of systems specifcally tailored to the task.\n",
    "\n",
    "With respect to the latter, the `CoreNLP` code uses rule-based tokenizer and lexer, which are tailored to deal with well-behaved texts the model was trained on.\n",
    "\n",
    "Trying the sentiment analyzer on the command line, it's easy to grt a sense of its sensitivity to spelling mistakes, the presence of hashtgs and emoticons, and the very specific language and abbreviations that people use on Twitter. By integrating some Twitter-specific tools for parsing (like [Noah Smith's group's](http://www.cs.cmu.edu/~ark/TweetNLP/)) should help further improve the score. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
